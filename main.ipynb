{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "75c2ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet, stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f755300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DoniZefironi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DoniZefironi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1150fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "\n",
    "df = df[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "351220de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e8c0c314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     20000 non-null  object\n",
      " 1   sentiment  20000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "25e975af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>19926</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4</td>\n",
       "      <td>10097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               20000     20000\n",
       "unique                                              19926         2\n",
       "top     Loved today's show!!! It was a variety and not...  negative\n",
       "freq                                                    4     10097"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "21f9fbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    0.50485\n",
       "positive    0.49515\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4be4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text: str) -> str:\n",
    "\n",
    "    word = [lemmatizer.lemmatize(i) for i in text.lower().split()]\n",
    "\n",
    "    return ' '.join(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d1892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stemmer_text(text: str) -> str:\n",
    "\n",
    "    word = [stemmer.stem(i) for i in text.lower().split()]\n",
    "\n",
    "    return ' '.join(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "054f2b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "815dfb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DoniZefironi\\AppData\\Local\\Temp\\ipykernel_16076\\202790638.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"sentiment\"].replace(\"positive\", 1).replace(\"negative\", 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "19995    0\n",
       "19996    0\n",
       "19997    1\n",
       "19998    1\n",
       "19999    0\n",
       "Name: sentiment, Length: 20000, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].replace(\"positive\", 1).replace(\"negative\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e6485336",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df[\"review\"], df[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4f22a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c62bb44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4945"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = DummyClassifier()\n",
    "\n",
    "pipe_dummy = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(max_features=10000, ngram_range=(1,2))),\n",
    "    (\"dummy_class\", DummyClassifier(strategy = \"stratified\"))\n",
    "])\n",
    "\n",
    "pipe_dummy.fit(X_train, y_train)\n",
    "dummy_pred = pipe_dummy.predict(X_test)\n",
    "\n",
    "acc_dummy = accuracy_score(y_test, dummy_pred)\n",
    "acc_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "224111df",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "important_words = {\"not\", \"nor\", \"no\", \"but\", \"very\", \"too\"}\n",
    "custom_stopwords = custom_stopwords - important_words\n",
    "\n",
    "custom_stopwords.update([\"film\", \"show\", \"movie\"])\n",
    "custom_stopwords = list(custom_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ec2e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89125\n",
      "[[1799  220]\n",
      " [ 215 1766]]\n"
     ]
    }
   ],
   "source": [
    "pipe_standart = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(max_features=10000, ngram_range=(1,2))),\n",
    "    (\"logistic_regress\", LogisticRegression(max_iter=1000, C = 1))\n",
    "])\n",
    "\n",
    "pipe_standart.fit(X_train, y_train)\n",
    "pred_standart = pipe_standart.predict(X_test)\n",
    "\n",
    "acc_standart = accuracy_score(y_test, pred_standart)\n",
    "\n",
    "print(acc_standart)\n",
    "print(confusion_matrix(y_test, pred_standart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8ac63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-20 слов для ПОЛОЖИТЕЛЬНЫХ отзывов:\n",
      "        feature  coefficient\n",
      "3385      great     6.246937\n",
      "2658  excellent     4.722599\n",
      "9801  wonderful     3.535491\n",
      "6190    perfect     3.497532\n",
      "1095       best     3.440686\n",
      "4976      loved     3.263925\n",
      "328     amazing     3.234522\n",
      "378         and     3.189124\n",
      "7936   the best     2.944554\n",
      "1321  brilliant     2.780257\n",
      "\n",
      "\n",
      "Топ-20 слов для ОТРИЦАТЕЛЬНЫХ отзывов:\n",
      "        feature  coefficient\n",
      "907         bad    -6.863064\n",
      "9842      worst    -5.837760\n",
      "890       awful    -5.391934\n",
      "1196     boring    -5.064837\n",
      "8371  the worst    -4.710332\n",
      "9414      waste    -4.574579\n",
      "7760   terrible    -4.423159\n",
      "5686    nothing    -4.162815\n",
      "6339       poor    -3.988298\n",
      "7579     stupid    -3.596936\n"
     ]
    }
   ],
   "source": [
    "vectorizer = pipe_standart.named_steps['vectorizer']\n",
    "model = pipe_standart.named_steps['logistic_regress']\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefficients = model.coef_[0]\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': coefficients\n",
    "})\n",
    "\n",
    "print(\"Топ-10 слов для ПОЛОЖИТЕЛЬНЫХ отзывов:\")\n",
    "print(coef_df.sort_values('coefficient', ascending=False).head(10))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Топ-10 слов для ОТРИЦАТЕЛЬНЫХ отзывов:\")\n",
    "print(coef_df.sort_values('coefficient', ascending=True).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320ed783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     \"vectorizer__max_features\": [5000, 10000, ],\n",
    "#     \"vectorizer__ngram_range\": [(1,1), (1,2)],\n",
    "#     \"logistic_regress__C\": [0.1, 1]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(pipe, param_grid, cv=3, n_jobs=-1, scoring=\"accuracy\")\n",
    "\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# print(grid_search.best_params_)\n",
    "# print(grid_search.best_score_)\n",
    "\n",
    "\n",
    "# {'logistic_regress__C': 1, 'vectorizer__max_features': 10000, 'vectorizer__ngram_range': (1, 2)}\n",
    "# 0.8830627607888785"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7668a619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88825\n",
      "[[1785  234]\n",
      " [ 213 1768]]\n"
     ]
    }
   ],
   "source": [
    "pipe_stopwords = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(max_features=10000, ngram_range=(1,2), stop_words=custom_stopwords)),\n",
    "    (\"logistic_regress\", LogisticRegression(max_iter=1000, C = 1))\n",
    "])\n",
    "\n",
    "pipe_stopwords .fit(X_train, y_train)\n",
    "pred_stopwords = pipe_stopwords .predict(X_test)\n",
    "\n",
    "acc_stopwords = accuracy_score(y_test, pred_stopwords)\n",
    "\n",
    "print(acc_stopwords)\n",
    "print(confusion_matrix(y_test, pred_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f9d242f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DoniZefironi\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['doe', 'ha', 'wa'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8885\n",
      "[[1789  230]\n",
      " [ 216 1765]]\n"
     ]
    }
   ],
   "source": [
    "pipe_lemma = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(max_features=10000, ngram_range=(1,2), stop_words=custom_stopwords, preprocessor=lemmatize_text)),\n",
    "    (\"logistic_regress\", LogisticRegression(max_iter=1000, C = 1))\n",
    "])\n",
    "\n",
    "pipe_lemma .fit(X_train, y_train)\n",
    "pred_lemma = pipe_lemma.predict(X_test)\n",
    "\n",
    "acc_lemma = accuracy_score(y_test, pred_lemma)\n",
    "\n",
    "print(acc_lemma)\n",
    "print(confusion_matrix(y_test, pred_lemma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3f3f970d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ 10 слов для ПОЛОЖИТЕЛЬНЫХ отзывов\n",
      "       features  coefficients\n",
      "3939      great      6.369287\n",
      "3124  excellent      5.164975\n",
      "901        best      4.221973\n",
      "5260      loved      3.971382\n",
      "9811  wonderful      3.675030\n",
      "6547    perfect      3.513304\n",
      "449     amazing      3.468076\n",
      "5246       love      3.288561\n",
      "6241   one best      3.213526\n",
      "1306  brilliant      3.072756\n",
      "\n",
      "Топ 10 слов для ОТРИЦАТЕЛЬНЫХ отзывов\n",
      "      features  coefficients\n",
      "747        bad     -6.897049\n",
      "9854     worst     -6.703153\n",
      "720      awful     -5.682396\n",
      "9608     waste     -5.155380\n",
      "1054    boring     -5.051520\n",
      "6130   nothing     -4.498059\n",
      "8683  terrible     -4.363235\n",
      "6742      poor     -3.980488\n",
      "9851     worse     -3.804077\n",
      "4312  horrible     -3.591422\n"
     ]
    }
   ],
   "source": [
    "vectorizer_lemma = pipe_lemma.named_steps['vectorizer']\n",
    "model_lemma = pipe_lemma.named_steps[\"logistic_regress\"]\n",
    "\n",
    "feature_names_lemma = vectorizer_lemma.get_feature_names_out()\n",
    "coefficients_lemma = model_lemma.coef_[0]\n",
    "\n",
    "coef_df_lemma = pd.DataFrame({\n",
    "    \"features\": feature_names_lemma,\n",
    "    \"coefficients\": coefficients_lemma\n",
    "})\n",
    "\n",
    "print(f\"Топ 10 слов для ПОЛОЖИТЕЛЬНЫХ отзывов\")\n",
    "print(coef_df_lemma.sort_values(\"coefficients\", ascending=False).head(10))\n",
    "\n",
    "print()\n",
    "print(f\"Топ 10 слов для ОТРИЦАТЕЛЬНЫХ отзывов\")\n",
    "print(coef_df_lemma.sort_values(\"coefficients\", ascending=True).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4c94796a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DoniZefironi\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'becaus', 'befor', 'doe', 'dure', 'ha', 'hi', 'movi', 'onc', 'onli', 'ourselv', 'themselv', 'thi', 'wa', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8835\n",
      "[[1784  235]\n",
      " [ 231 1750]]\n"
     ]
    }
   ],
   "source": [
    "pipe_stem = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(max_features=10000, ngram_range=(1,2), stop_words=custom_stopwords, preprocessor=stemmer_text)),\n",
    "    (\"logistic_regress\", LogisticRegression(max_iter=1000, C = 1))\n",
    "])\n",
    "\n",
    "pipe_stem.fit(X_train, y_train)\n",
    "pred_stem = pipe_stem.predict(X_test)\n",
    "\n",
    "acc_stem = accuracy_score(y_test, pred_stem)\n",
    "\n",
    "\n",
    "print(acc_stem)\n",
    "print(confusion_matrix(y_test, pred_stem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8a3f22a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standart model: 0.89125\n",
      "Standart model + stopwords: 0.88825\n",
      "Lemmatision model + stopwords: 0.8885\n",
      "Stemping model + stopwords: 0.8835\n"
     ]
    }
   ],
   "source": [
    "print(f\"Standart model: {acc_standart}\")\n",
    "print(f\"Standart model + stopwords: {acc_stopwords}\")\n",
    "print(f\"Lemmatision model + stopwords: {acc_lemma}\")\n",
    "print(f\"Stemping model + stopwords: {acc_stem}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dd41e4",
   "metadata": {},
   "source": [
    "Best result gives a **standart model**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
